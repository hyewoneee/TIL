# 도서리뷰 Real World HTTP 리얼 월드 HTTP
책을 읽고 정리하는 공간

# 목차

- [x] 1장. HTTP/1.0의 신택스: 기본이 되는 네 가지 요소
- [] 2장. HTTP/1.0의 시맨틱스: 브라우저 기본 기능의 이면
- [] 3장. GO 언어를 이용한 HTTP/1.0 클라이언트 구현
- [] 4장. HTTP/1.1의 신택스: 고속화와 안전성을 추구한 확장
- [] 5장. HTTP/1.1의 시맨틱스: 확장되는 HTTP의 용도
- [] 6장. Go 언어를 이용한 HTTP1.1 클라이언트 구현
- [] 7장. HTTP/2의 신택스: 프로토콜 재정의
- [] 8장. HTTP.2의 시맨틱스: 새로운 활용 사례
- [] 9장. Go 언어를 이용한 HTTP/2, HTTP5 프로토콜 구현
- [] 10장. 보안: 브라우조를 보호하는 HTTP의 기능
- [] 11장. 클라이언트 시점에서 보는 RESTful API

# 1장. HTTP/1.0의 신택스: 기본이 되는 네 가지 요소

HTTP를 데이터의 상자로서 보면 통신 내용을 몇 가지 요소로 나눌 수 있다.

이 장에서는 다음 네 가지 기본 요소에 초점을 맞춰 소개한다.

- 메서드와 경로
- 헤더
- 바디
- 스테이터스 코드

HTTP를 다루는 도구로서 curl 커맨드 사용법도 소개한다.

curl 커맨들르 사용하면 원하는대로 서버에 요청을 보낼 수 있다.

### HTTP/0.9에서 1.0으로의 여정

HTTP/0.9는 매우 단순했지만 `'브라우저가 문서를 요청하면, 서버는 데이터를 반환한다'` 라는 웹의 기본 뼈대는 이미 이 시점에서 완성됐다.

그렇지만 이 프로토콜로는 할 수 없는 일이 많았다.

- 하나의 문서를 전송하는 기능밖에 없었다.
- 통신되는 모든 내용은 HTML 문서로 가정했으므로, 다운로드할 콘텐츠의 형식을 서버가 전달할 수단이 없었다.
- 클라이언트 쪽에서 검색 이외의 요청을 보낼 수 없었다.
- 새로운 문장을 전송하거나 갱신 또는 삭제할 수 없었다.

그 밖에도 요청이 올바른지 혹은 서버가 올바르게 응답했는지 아는 방법도 없었다.

1992년 버전에서는 단순버전(0.9 호환모드)과 전 기능(1.0과 거의 같다) 버전으로 두 종류의 요청 형식이 있었다.

요청의 변경된 점은 다음과 같다.

- 요청 시 메서드가 추가됐다(GET).
- 요청 시 HTTP 버전이 추가됐다(HTTP/1.0).
- 헤더가 추가됐다(Host, User-Agent, Accept).

### HTTP의 조상(1) 전자메일

HTTP에도 이 전자메일과 똑같은 형식의 헤더가 도입됐다.

헤더는 서버와 클라이언트 사이에 필요한 추가 정보, 지시나 명령, 당부 등을 쓰는 장소다.

우선 클라이언트가 서버에 보내는 헤더다

**User-Agent**

클라이언트가 자신의 애플리케이션에 이름을 넣는곳.

curl 커맨드를 사용하면 curl/7.48.0과 같은 문자열이 들어가며

서버는 이곳의 이름을 보고 응답을 전환하기도 한다.

**Referer**

서버에서  참고하는 추가정보

클라이언트가 요청을 보낼 때 보고 있던 페이지의 URL을 보낸다.

페이지의 참조원을 서버가 참조하는데 이용한다.

**Authorization**

특별한 클라이언트에만 통신을 허가할 때 인증 정보를 서버에서 전달한다.

RFC에서 몇 가지 표준 형식(Basic/Digest/Bearer)을 정했지만, 아마존 웹 서비스나 깃허브 API 등에서는 웹 서비스 자체 표기를 요구하기도 한다.

서버에서 클라이언트로 보낼 때 부여하는 헤더는 다음과 같은 것이 있다.

**Content-Type**

파일 종류를 지정

여기에는 MIME 타입이라는 식별자를 기술한다.

MIME 타입은 전자메일을 위해 만들어진 식별자다.

**Content-Length**

바디크기

**Content-Encoding**

압축이 이루어진 경우 압축 형식을 설명

**Date**

문서 날짜

### MIME 타입

MIME 타입은 파일의 종류를 구별하는 문자열로, 전자메일을 위해 만들어졌다.

파일 종류에 따라 브라우저 화면에 표시하거나 `'저장'` 대화창을 표시하는 기능을 제공하는데,

이때 파일 종류를 나타내는 식별자가 MIME 타입이다.

### Content-Type과 보안

브라우저 세계에서는 앞에서 소개한 것처럼 파일 종류를 특정할 때 Content-Type 헤더에서 지정된 MIME 타입을 사용 

인터넷 익스플로러는 인터넷 옵션에 따라 MIME 타입이 아닌 내용을 보고 파일 형식을 추측하려고 한다.

이런 동작을 `콘텐트 스피닝(content sniffing)` 이라 한다.

이때 서버 설정이 잘못된 경우에도 제대로 표시되므로 얼핏 사용자에게 장점이 있는것처럼 여겨질 수 있지만, 원래 텍스트로만 표시돼야 하는 `text/plain` 파일인데도 HTML과 자바스크립트가 적혀있으면 브라우저가 파일을 실행해버리는 일도 있다.

뜻밖에 보안의 구멍이 될 수 있다.

서버에서는 다음과 같은 헤더를 전송해 브라우저가 추측하지 않도록 지시하는 것이 현재 주류의 방법이다.

`X-Content-Type-Option: nosniff`

### 전자메일과의 차이

헤더를 설명하면서 전자메일 포맷을 소개했다. HTTP와 비교해보자

- '헤더' + '본문' 구조는 같다.
- HTTP 요청에서는 선두에 '메서드+패스' 행이 추가된다.
- HTTP  응답에서는 선두에 스테이터스 코드가 추가된다.

### 메서드

 HTTP/1.0으로 통신할 때 전송되는 GET 부분은 메서드로 불린다.

- GET : 서버에 헤더와 콘텐츠 요청
- HEAD: 서버에 헤더만 요청
- POST: 새로운 문서 투고
- PUT: 이미 존재하는 URL의 문서를 갱신
- DELETE: 지정된 URL의 문서를 삭제

curl 커멘드로 메서드를 전송할 때는 `--request=` 메서드 혹은 그 단축형인 `-X` 메서드를 사용

	curl --http1.0 -X POST http://localhost:18888/greeting

### 스테이터스 코드

**100번대**

처리가 계속됨을 나타낸다

1xx계열은 특수한 용도로 사용

**200번대**

성공했을 때의 응답

**300번대**

서버에서 클라이언트로의 명령

오류가 아니라 정상 처리의 범주

리디렉트나 캐시 이용을 지시

**400번대**

클라이언트가 보낸 요청에 오류가 있다.

**500번대**

서버 내부에서 오류가 발생

### 리다이렉트

300번대 스테이터스의 일부는 서버가 브라우저에 대해 리디렉트하도록 지시하는 스테이터스 코드다.

300 이외의 경우는 **Location** 헤더를 사용해 리디렉트할 곳을 서버에서 클라이언트로 전달

영구적인지 일시적인지는 이동하는 이전 페이지가 이후에도 존재하는지로 분류한다.

**영구적**

새 도메인을 얻어 서버의 콘텐츠를 이동한 경우나 HTTP로 운영되던 페이지를 HTTPS로 전환한 경우에는 에전 페이지를 볼 일이 없다.

**일시적**

점검 기간에만 요청을 관리 화면으로 리디렉트할 경우 점검이 끝나면 복구해 다시 활성화할 것

**301/308**

요청된 페이지가 다른 장소로 이동했을 때 사용

영구적으로 이동

검색 엔진도 이 응답을 받으면 기존 페이지의 평가를 새로운 페이지로 게승한다.

구글은 검색 엔진에 페이지 이동을 전하는 수단으로써 **301**을 사용할 것을 권장

**302/307**

일시적인 이동

모바일 전용 사이트로 이동하거나 관리 페이지를 표시

**303**

요청된 페이지에 반환할 콘텐츠가 없거나 혹은 원래 반환할 페이지가 따로 있을 때, 그쪽으로 이동시키려고 사용한다.(로그인 페이지를 사용해 로그인한 후 원래 페이지로 이동하는 경우에 사용)

클라이언트는 **Location** 헤더 값을 보고, 다시 요청한다

재전송할 때는 헤더 등도 다시 보낸다.

curl 커맨드에 `-L` 을 부여하면, 응답이 300번대고 게다가 응답 헤더에 **Location** 헤더가 있으면 그 헤더에서 지정된 URL에 다시 요청을 보낸다.

또한 스테이터스 코드가 **301, 302, 303**이고 **GET** 이외의 메서드인 경우에는 **GET**으로 리디렉트를 다시 보낸다.

메서드를 바꿀수 없게 하는 옵션(—post301, —post302, —post303)도 있다.

기본으로 최대 50번 까지 리디렉트 한다.

리디렉트 횟수도 `--max-redirs` 옵션으로 지정할 수 있다.


### URL의 구조

URL은 아래와 같은 요소로 구성됨

**스키마://호스트명/경로**

- 스키마: https
- 호스트명: www.oreilly.co.jp
- 경로: index.shtml

URL 사양에 포함되는 모든 요소가 들어간 예제는 다음과 같은 형식

**스키마://사용자:패스워드@호스트명:포트/경로#프래그먼트?쿼리**

자주 보는 스키마로는 http외에 통신 경로가 암호화 되는 https, 메일러를 시작하는 mailot가 있다.

브라우저는 스키마를 보고 적절한 접속 방법을 선택해야한다.

실제로 통신하는 곳은 **호스트명**으로 지정된 서버이다.

포트는 아파트 등의 현관 우편함 같은 것이다.

주소(호스트명으로 찾아온 IP주소) 마다 65,535개의 포트가 있다.

같은 주소라도 포트가 다르면 독립적으로 복수의 서버를 운영해 서비스를 제공할 수 있다.

포트가 새얅되면 스키마별 기본 포트를 사용

HTTP : 80번 포트

HTTPS: 443번 포트

프래그먼트는 HTML에서는 페이지 내 링크의 앵커를 지정하는데 쓰인다.

쿼리는 검색 용어를 지정하거나 포시하고 싶은 웹페이지에 대해서 특정 파라미터를 부여하는데 사용 

URL은 주소를 지정하는 데 사용하지만, 동시에 `'사용자가 읽는 문장'`  이기도 하다.

### 바디

HTTP/0.9 사양에서는 요청에 데이터를 포함할 수 없었다.

응답은 파일 콘텐츠 자체였지만, 1.0에서는 요청과 응답 양쪽에 헤더가 포함돼 바디와 헤더를 분리할 필요가 있다. 또한 요청에도 콘텐츠를 포함할 수 있게 돼 새로운 역할이 늘어났다.

헤더 끝에 빈 줄을 넣으면 그 이후는 모두 바디가 된다.

이 구조는 전자메일과 똑같지만, 전송할 때 데이터를 저장하는 포맷이 두 종류로 용도에 맞게 구분할 필요가 있다.

    헤더1: 헤더 값 1
    헤더2: 헤더 값 2
    Content-Length: 바디의 바이트 수
    
    여기서부터 지정된 바이트 수만큼 바디가 포함된다.

한 번 응답할 때마다 한 파일만 반환하기 때문에 HTTP에서 응답의 바디는 단순하다.

속도를 위해 바디를 압축하는 경우가 있다.

이때는 Content-Encoding에서 지정된 압축 알고리즘으로 읽어 온 바디의 데이터를 전개할 필요가 있다.

이 경우 Content-Length는 압축 전 콘텐츠 길이가 아니라 압축 후 통신 데이터 크기다.

서버와 통신이 확립된 소켓에서 클라이언트가 읽는 바이트 수는 Content-Length에 적힌 데이터 길이로 압축되지 않았을 때와 다르지 않다.
---
# 2장. HTTP/1.0의 시맨틱스: 브라우저 기본 기능의 이면

이 장에서는 curl 커맨드를 이용해 브라우저의 동작을 이해한다.

### 단순한 폼 전송(x-www-form-urlencoded)

curl 커맨드의 `-d` 옵션을 사용해 폼으로 전송할 데이터를 설정할 수 있다.

curl 커맨드는 `-d` 옵션이 지정되면 브라우저와 똑같이 헤더로 Content-Type:application/x-www-form-rulencoded를 설정

`-d` 옵션으로 보낼 경우 지정된 문자열을 그대로 연결

구분문자인 `&` 와 `=` 이 있어도 그대로 연결해버리므로, 읽는 쪾에서 바르게 원래 데이터 세트로 복원할 수 없다.

에를 들어 `Head First PHP & MYSQL` 이라는 서적명을 넣어보면, 어디서 구분해야 할 지 알기 어려워진다.

### 폼을 이용한 파일 전송

HTML의 폼에서는 옵션으로 멀티파트 폼 형식이라는 인코딩 타입을 선택할 수 있다.

보통 HTTP 응답은 한 번에 한 파일씩 반환하므로, 빈 줄을 찾아 그곳부터 `Content-Length` 로 지정된 바이트 수만큼 읽기만 하면 데이터를 통째로 가져올 수 있다.(파일의 경계를 신경쓸 필요가 없다)

멀티파트를 이용하는 경우는 한 번의 요청으로 복수의 파일을 전송할 수 있으므로 받는 쪽에서 파일을 나눠야한다.

`-d` 대신에 `-F` 를 사용하는 것만으로 curl 커맨드는 `enctype="multipart/form-data"`가 설정된 폼과 같은 형식으로 송신한다.

`-d` 와  `-F` 를 섞어 쓸 수는 없다. 

파일 전송은 `@` 를 붙여 파일 이름을 지정하면, 그 내용을 읽어와서 첨부한다.

아래와 같이 전송할 파일명과 파일 형식을 수동으로 설정할 수 있다.

type과 filename은 동시에 설정할 수 있다.

	# 파일 내용을 test.txt에서 최득. 파일명은 로컬 파일명과 같다. 형식도 자동 설정
	curl --http1.0 -F attachment-file@test.txt http://localhost:18888
	
	# 파일 내용을 test.txt에서 취득. 형식은 수동으로 지정.
	curl --http1.0 -F "attachment-file@test.txt;type=text/html" http://localhost.18888
	
	# 파일 내용을 test.txt에서 취득. 파일명은 지정한 파일명을 이ㅛㅇㅇ.
	curl --http1.0 -F "attachment-file@test.txt;filename-sample.txt"
	http://localhost:18888

### 폼을 이용한 리디렉트

1장의 1.6 리디렉트에서는 300번대 스테이터스 코드를 사용한 리디렉트를 소개했다.

하지만 이 방법에는 몇 가지 제한이 있다.

- 1장의 URL 항목에서 설명한 것처럼 URL에는 2천 자 이내라는 기준이 있어, GET의 쿼리로 보낼 수 있는 데이터양에 한계가 있다.
- 데이터가 URL에 포함되므로, 전송하는 내용이 액세스 로그 등에 남을 우려가 있따.

이런 분제를 피하고자 종종 이용되는 방법이 HTML의 폼을 이용한 리디렉트다.

서버로 부터는 리디렉트할 곳으로 보내고 싶은 데이터가 `<input type="hidden">` 태그로 기술된 HTML이 되돌아 온다. 

폼에서 보내는 곳이 리디렉트 할 곳이다.

브라우저가 이 HTML을 열면, 로드 직후 발생하는 이벤트로 폼을 전송하므로 즉시 리디렉트해 이동하게 된다.

이 방법의 장점은 인터넷 익스플로러에서도 데이터양에 제한이 없다는 점이다.

단점으로는 순간적으로 빈 페이지가 표시된다는 것과 전환 버튼이 표시되긴 하지만 자바스크립트가 비활성화되어 있으면 자동으로 전환되지 않는다는 점이다.

### 콘센트 니고시에이션

콘센트 니고시에이션은 통신 방법을 최적화하고자 하나의 요청 안에서 서버와 클라이언트가 서로  최고의 설정을 공유하는 시스템이다.

콘센트 니고시에이션에는 헤더를 이용한다.

	요청 헤더            응답                              니고시에이션 대상						
	Accept             Content-Type 헤더                 MIME 타입
	Accept-Language    Content-Language 헤더/html 태그    표시언어
	Accept-Charset     Content-Type 헤더                 문자의 문자셋
	Accept-Encoding    Content-Encoding 헤더             바디 압축

### 압축을 이용한 통신 속도 향상

콘텐츠 압축은 전송 속도 향상을 위한 것이다.

콘텐츠 내용에 따라 다르지만, 현재 일반적으로 사용되는 압축 알고리즘을 적용하면 텍스트 파일은 1/10 크기로 압축된다.

같은 기호가 반복해서 나오는 JSON 이라면 1/20 정도로 압축 할 수 있다.

통신에 걸리는 시간보다 압축과 해제가 짧은 시간에 이루어지므로, 압축을 함으로써 웹 페이지를 표시할 때 걸리는 전체적인 처리 시간을 줄일 수 있다.

콘텐츠 압축은 전송 속도 향상뿐만 아니라 이용 요금에도 영향을 미친다.

콘텐츠를 압축하면 비용부다도 줄어들고 모바일 단말은 전파 송수신에 전력을 많이 소비하므로, 전력 소비가 줄어드는 효과도 기대할 수 있다.

콘텐츠 압축 니고시에이션은 모두 HTTP의 헤더 안에서 완료한다.

우선 클라이언트가 수용 가능한 압축방식을 헤더에서 지정한다.

여기에서는 `deflate` 와 `gzip` 두가지를 지정햇다.

`Accept-Encoding: deflate, gzip`

curl 커맨드에서 `--compressed` 옵션을 지정하면 , `-H` 옵션으로 위 헤더를 기술한 것과 같다

	curl --http1.0 --compressed http://localhost:18888

서버는 전송받은 목록 중 지원하는 방식이 있으면, 응답할 때 그 방식으로 압축하거나 미리 압축된 콘텐츠를 반환한다.

서버가  `gzip` 을 지원하면, 조금 전에 받은 요청에 대한 응답으로 다음과 같은 헤더가 부여된다.

콘텐츠의 데이터양을 나타내는 `Content-Lenhth` 헤더는 압축된 파일 크기다.

`Content-Encoding: gzip` 

서버에서 클라이언트로 첫 번째 웹 페이지를 반환할 대 `Accept-Encoding`헤더를 부여하고, 그런 다음 클라이언트에서 무언가 업로드 할 때 `Content-Encoding` 을 부여한다.

지금의 고속화 방식과는 대조적으로 헤더가 이용된다. 

요청, 응답 양쪽에서 똑같이 헤어 구조가 이용되므로 이처럼 간단하게 구현할 수 있다.

### 쿠키

쿠키란 웹 사이트의 정보를 브라우저 쪽에 저장하는 작은 파일이다.

서버가 클라이언트(브라우저)에 `'이 파일 보관해줘'` 라고 쿠키 저장을 지시한다.

쿠키도 HTTP 헤더를 기반으로 구현됐다.

서버에서는 다음과 같이 응답 헤더를 보낸다.

	Set-Cookie: LAST_ACCESS_DATE=Jul/31/2016
	Set-Cookie: LAST_ACCESS_TIME=12:04

각각 `이름=값` 형식으로 회신했는데, 클라이언트는 이 값을 저장해 둔다.

다음번에 방문할 때는 다음과 같은 형식으로 보내자.

서버는 이 설정을 읽고,  클라이언트가 마지막으로 액세스한 시간을 알 수 있다.

	Cookie: LAST_ACCESS_DATE=Jul/31/2016
	Cookie: LAST_ACCESS_TIME=12:04

브라우저에서도 자바스크립트로 쿠키를 읽어내거나 서버에 보낼 때 쿠키를 설정할 수 있다.

개발자 도구를 열고 `document.cookie` 속성을 보면 쿠키가 문자열 형식으로 들어있는 것을 알 수 있다.

쿠키는 헤더를 바탕으로 만들어졌으므로 curl 커맨드를 사용할 때도 헤더로서 받은 내용을  `Cookie`에 넣고 재전송함으로써 실현할 수 있지만,

쿠키를 위한 전용 옵션도 있다.

`-c/--cookie-jar` 옵션으로 지정한 파일에 수신한 쿠키를 지정하고

`-b/--cookie` 옵션으로 지정한 파일에서 쿠키를 읽어와 전송한다.

브라우저처럼 동시에 송수신하려면 둘 다 지정해야한다.

`-b/--cookie` 옵션은 파일에서 읽기만 하는 게 아니라 개별 항목을 추가할 때도 사용할 수 있다.

	curl --http1.0 -c cookie.txt -b cookie.txt -b "name=value"
	http://example.com/helloworld

### 쿠키의 잘못된 사용법

쿠키는 편리한 기능이지만, 몇 가지 제약이 있어 적절하지 않은 사용법이 있다.

우선 영속성 문제

쿠키는 어떤 상황에서도 확실하게 저장되는 것은 아니다.

비밀모드 혹은 브라우저의 보안 설정에 따라 세션이 끝나면 초기화 되거나 쿠키를 보관하라는 서버의 지시를 무시하기도 한다.

서버가 쿠키를 데이터베이스 대신으로 쓸 수 는 없다.

쿠키가 초기화 되면 저장된 데이터는 사라지기 때문에 사라지더라도 문제가 없는 정보나 서버 정보로 복원할 수 있는 자료를 저장하는 용도에 적합하다.

또한 용량문제도 있다.

쿠키의 최대 크기는 4킬로바이트 사양으로 정해져 있어 더 보낼 수 는 없다.

쿠니는 헤더로서 항상 통신에 부가되므로 통신량이 늘어나는데, 통신량 증가는 요청과 응답 속도 모두에 영향을 미친다.

제한된 용량과 통신량 증가는 데이터베이스로 사용하는데 제약이 된다.

보안문제

`secure` 속성을 부여하면 HTTPS 프로토콜로 암호화된 통신에서만 쿠키가 전송되지만,

HTTP 통신에서는 쿠키가 평문으로 전송된다.

매 요청 시 쿠키가 송수신되는데, 보여선 안되는 정보등이 포함되면 노출될 위험성이 있다.

암호화된다고해도 사용자가 자유롭게 접근할 수 있는 것도 문제이다.

원리상 사용자가 쿠키를 수정할수도 있으므로, 시스템에서 필요한 정보가 수정되면 오작동으로 이어지는 민감한 정보를 넣는 것도 적합하지 않다. 

정보를 넣을 때는 서명이나 암호화처리가 필요하다.

기본적으로는 인증 정보나 사라져도 문제가 없는 정보만 쿠키에 넣는 편이 좋다.

### 쿠키에 제약을 주다

클라이언트는 서버가 보낸 쿠키를 로컬 스토리지에 저장하고, 같은 URL로 접속할 때 저장된 쿠키를 읽고 요청 헤더에 넣는다.

HTTP 클라이언트는 이 속성을 해석해 쿠키 전송을 제어할 책임이 있다.

속성은 세미콜론으로 구분하여 나열한다.

속성은 대문자와 소문자를 구별하지 않으므로 모두 소문자로 써도 유효하다

**Expires, Max-Age 속성**

쿠키의 수명을 설정

Max-Age는 초 단위로 지정.

현재 시각에서 지정된 초수를 더한 시간에서 무효가 된다.

**Domain 속성**

클라이언트에서 쿠키를 전송할 대상 서버

쿠키를 발행한 서버가 된다.

**Path 속성**

클라이언트에서 쿠키를 전송할 대상 서버의 경로

쿠키를 발행한 서버의 경로

**Secure 속성**

https로 프로토콜을 사용한 보안 접속일 때만 클라이언트에서 서버로 쿠키를 전송

쿠키는 URL을 키로 전송을 결정하므로, DNS 해킹으로 URL을 사칭하면 의도치 않은 서버에 쿠키를 전송할 위험이 있다.

DNS 해킹은 기기를 조작하지 않고도 무료 와이파이 서비스 등으로 속여 간단히 할 수 있다.

Secure 속성을 붙이면 http 접속일 때는 브라우저가 경고를 하고 접속하지 않아 정보 유출을 막게 된다.

**HttpOnly 속성**

쿠키를 소개할 때 쿠키를 자바스크립트로 다룰 수 있다고 설명했지만, 이 속성을 붙이면 자바스크립트 엔진으로부터 쿠키를 감출 수 있다.

크로스 사이트 스크립팅등 악의적인 자바스크립트가 실행되는 보안 위험에 대한 방어가 된다.

**SameSite 속성**

이 속성은 RFC에는 존재하지 않는다.

크롬 브라우저 버전 51에서 도입한 속성으로, 같은 오리진(출저)의 도메인에 전송된다.

### 인증과 세션

인증에는 몇 가지 방식이 있다.

유저명과 패스워드를 매번 클라이언트에서 보내는 방식 두 가지를 먼저 소개한다.

### BASIC 인증과 Digest 인증

가장 간단한 것이 BASIC 인증이다.

BASIC 인증은 유저명과 패스워드를 BASE64로 인코딩 한 것

BASE64 인코딩은 가역변환이므로 서버로부터 복원해 원래 유저명과 패스워드를 추출할 수 있다.

추출된 정보를 서버의 데이터베이스와 비교해서 정상 사용자인지 검증

단 SSL/TLS 통신을 사용하지 않은 상태에서 통신이 감청되면 손쉽게 로그인 정보가 유출된다.

BASIC보다 강력한 Digest 인증이다.

Digest 인증은 해시 함수(A→B는 쉽게 계산할 수 있지만, B→A는 쉽게 계산할 수 없다)를 이용한다.

브라우저가 보호된 영역에 접속하려고 하면, **401 Unauthrized**라는 스테이터스 코드로 응답이 돌아온다.

이때 아래와 같은 헤더가 부여된다

	WWW-Authenticate: Digest realm="영역명", nonce="1234567890", algorith=MD5, qop="auth"

`realm` 은 보호되는 영역의 이름으로, 인증창에 표시된다.

`nonce`는 서버가 매번 생성하는 랜덤한 데이터다

`qop` 는 보호 수준을 나타낸다.

클라이언트는 이곳에서 주어진 값과 무작위로 생성한 `cnonce` 를 바탕으로 다음처럼 계산해서 response를 구한다.

클라이언트에서는 생성한 cnonce와 계산으로 구한 response를 부여해 한데 모으고, 다음과 같은 헤더를 덧붙여 재요청을 보낸다.

서버측에서도 이 헤더에 있는 정보와 서버에 저장된 유저명, 패스워드로 같은 계산을 실시한다.

재발송된 요청과 동일한 response가 계산되면 사용자가 정확하게 유저명과 패스워드를 입력했음을 보증할 수 있다.

이로써 유저명과 패스워드 자체를 요청에 포함하지 않고도 서버에서 사용자를 올바르게 인증할 수 있게 된다.

### 쿠키를 사용한 세션 관리

지금은 BASIC 인증과 Digest 인증 모두 많이 사용되지 않는다.

- 특정 폴더 아래를 보여주지 않는 방식으로만 사용할 수 있어, 톱페이지에 사용자 고유 정보를 제공할 수 없다.
- 톱페이지에 사용자 고유 정보를 제공하려면 톱페이지도 보호할 필요가 있어, 톱페이지 접속과 동시에 로그인 창을 표시해야한다. 처음 방문하는 사용자에게 친절한 톱페이지는 아니다.
- 요청할 때마다 유저명과 패스워드를 보내고 계산해서 인증할 필요가 있다. 특히 Digest 인증 방식은 께산량도 많다.
- 로그인 화면을 사용자화할 수 없다. 최근에는 피싱 대책으로 (미리 가지고 있는) 사용자 ID에 대응하는 이미지를 표시하는 등 가짜 사이트가 아님을 사용자가 인지할 수 있는 시스템을 제공하는 사이트가 있따.
- 명시적인 로그오프를 할 수 없다.
- 로그인한 단말을 식별할 수 없다. 게임등 동시 로그인을 막고 싶은 서비스나 구글처럼 미등록 단말로 로그인할 때 보안 경고를 등록된 메일로 보내는 기능이 있는 웹 서비스도 있다.

최근 많이 사용되는 방식은 폼을 이용한 로그인과 쿠키를 이용한 세션 관리를 조합이다.

클라이언트는 폼으로 ID와 비밀번호를 전송한다.

Digest 인증과 달리, 유저 ID와 패스워드를 직접 송신하므로 SSL/TLS이 필수다.

서버 측에서는 유저 ID와 패스워드로 인증하고 문제가 없으면 세션 토큰을 발행한다.

서버는 세션 토큰을 관계형 데이터베이스나 키 밸류형 데이터베이스에 저장해둔다.

토큰은 쿠키로 클라이언트에 되돌아간다.

두 번째 이후 접속에서는 쿠키를 재전송해서 로그인된 클라이언트임을 서버가 알 수 있다.

### 서명된 쿠키를 이용한 세션 데이터 저장

쿠키는 통신량을 증가시키므로 조심하자고 설명했지만, 원래의 용ㅗ대로 스토리지로서 사용할 수 있다.

웹 애플리케이션 프레임워크는 영속화 데이터를 읽고 쓰는 OR 매퍼 등의 시스템과 함께 휘발서 높은 데이터를 다루는 세션 스토리지 기능을 갖추고 있다.

통신 속도가 빨라지고 웹사이트 자체의 데이터양도 많이 늘어나면서, 쿠키의 데이터양 증가는 걱정할 필요가 없어졌다.

그래서 쿠키를 사용한 데이터 관리 시스템도 널리 사용되기 시작했다.

시스템에서 변조되지 않도록 클라이언트에 전자 서명된 데이터를 보낸다.

클라이언트가 서버로 쿠키를 재전송하면서 서버는 서명을 확인한다.

서명하는 것도 서명을 확인하는 것도 서버에서 하므로, 클라이언트는 열쇠를 갖지 않는다.

공개 키와 비밀 키 모두 서버에 있다.

이 시스템의 장점은 서버 측에서 데이터저장 시스템을 준비할 필요가 없다.

서버를 상세하게 기능단위로 나누는 마이크로서비스라도 세션 스토리지 암호화 방식을 공통화해두면 따로 데이터스토어를 세우지 않고 세션 데이터를 읽고 쓸 수 있게 된다.

클라이언트 입장에서 보면 서버에 액세스해서 조작한 결과가 쿠키로 저장된다.

쿠키를 갖고 있는 한 임시 데이터가 유지된다.

다만 전통적인 맴캐시드(mamcached)라든지 관계형 데이터베이스를 이용하는 세션 스토리지와 달리, 같은 사용자라도 스마트폰과 컴퓨터로 각각 접속한 경우 데이터가 공유되지 않는다.

### 프록시

**프록시**

- 통신 내용을 이해한다.
- 필요에 따라서 콘텐츠를 수정하거나 서버 대신 응답한다.

**게이트웨이**

- 통신 내용을 그대로 전송한다.
- 내용의 수정도 불허한다.
- 클라이언트에서는 중간에 존재하는 것을 알아채서는 안된다.

프록시는 HTTP등의 동신을 중계한다.

때로는 각 종 부가 기능을 구현한 경우도 있다.

- 캐시 기능이 있는 프록시를 조직의 네트워크 출입구에 설치하면, 콘텐츠를 저장한 웹 서버의 부담은 줄이고 각 사용자가 페이지를 빠르게 열람할 수 있게 하는 효과가 있다.
- 외부 공격으로부터 네트워크를 보호하는 방화벽 역할
    - 저속 통신 회선용으로 데이터를 압축해(이미지 화질은 떨어진다) 속도를 높이는 필터나 콘텐츠 필터링 등에도 프록시가 이용된다.

프록시 구조는 단순해서 `GET`  등의 메서드 다음에 오는 경로명 형식만 바뀐다.

프록시를 설정하면 스키마가 추기돼, `http://` 나 `https://` 로 시작되는 URL 형식이 된다.

프록시용 통신은 중계할 곳으로 요청을 리디렉트하고 결과를 클라이언트에 반환한다.

프록시 서버가 악용되지 않도록 인증을 이용해 보호하는 경우가 있다

이런 경우는 `Proxy-Authenticate` 헤더에 인증 방식에 맞는 값이 들어간다.

중계되는 프록시는 중간의 호스트 IP 주소를 특정 헤더에 기록해 간다.

 소개한다.

## 캐시

콘텐츠가 변경되지 않았을 땐 로컬에 저장된 파일을 재사용함으로써 다운로드 횟수를 줄이고 성능을 높이는 `캐시` 매너니즘이 등장했다.

### Expires

통신 자체를 없애는 방법이 HTTP/1.0에 도입되었으며, **Expires** 헤더를 이용한다.

`Expires` 헤더에는 날짜와 시간이 들어간다.

클라이언트는 지정한 기한 내라면 캐시가 `신선` 하다고 판단해 강제로 캐시를 이용한다.(요청을 아예 전송하지 않는 것, 캐시의 유효기간이 지났으면 캐시가 신선하지 않다고 판단)

`3초 후 콘텐츠 유효 기간이 끝난다` 라고 설정했어도 3초 후에 마음대로 리로드하지는 않는다.

여기에 설정된 날짜와 시간은 어디까지나 접속을 할지 말지 판단할 때만 사용한다.

또한 `뒤로 가기 버튼`등으로 방문이력을 조작하는 경우는 기한이 지난 오래된 콘텐츠가 그대로 이용될 수 있다.

### Pragma: no-cache

클라이언트가 프록시 서버에 지시할 수 있다.

지시를 포함한 요청 헤더가 들어갈 곳으로서 HTTP/1.0 부터 `Pragma 헤더` 가 정의되어 있다.

`Pragma` 헤더에 포함할 수 있는 페이로드로 유일하게 HTTP 사양으로 정의돈 것이 `no-cache`다.

`no-cache`는 `요청한 콘텐츠가 이미 저장돼 있어도, 원래 서버(오리진 서버)에서 가져오라` 고 프록시 서버에 지시하는 것

`no-cache` 는 HTTP/1.1에 이르러 `Cache-Control` 로 통합됐지만 1.1 이후에도 하위 호환성 유지를 위해 남아있다.

캐시 매커니즘에는 `Pragma: no-cache` 처럼 클라이언트에서 지시하는 것이나 프록시에 대해 지시하는 것도 몇 가지 있지만 그다지 적극적으로 사용되지 않음

프록시가 어느 정도 지시를 이해하고 기대한 대로 동작할지 보증할 수도 없음

중간에서 프록시 하나라도 `no-cache` 를 무시한다면 기대한 대로 동작하지 않는다.

HTTP/2가 등장한 이후로는 보안 접속 비율이 증가했다.

보안 통신에는 프록시가 통신 내용을 감시할 수 없고 중계만 할 수 있다.

프록시의 캐시를 외부에서 적극적으로 관리하는 의미가 이제 없다고도 말할 수 있다.

### ETag 추가

동적으로 바뀌는 요소가 늘어날수록 날짜를 근거로 캐시의 유효성을 판단하기 어려워진다.

그럴 때 사용할 수 있는것이 **RFC 2068**의 HTTP/1.1에서 추가된 `ETag(entity tag)` 다.

`ETag`는 순차적인 갱신 일시가 아니라 파일의 해시 값으로 비교한다.

일시를 이용해 확인할 때 처음처럼 서버는 응답에 `ETag` 헤더를 부여 

두 번째 이후 다운로드 시 클라이언트는 `If-None-Match` 헤더에 다운로드된 캐시에 들어 있던 `ETag` 값을 추가해 요청한다.

서버는 보내려는 파일의 `ETag` 와 비교해서 같으면 **304 Not Modified**로 응답한다.

여기까지는 HTTP/1.0에도 있었던 캐시 제어 구조이다.

### Cache-Control(1)

`ETag` 와 같은 시기에 HTTP/1.1에서 추가된 것이 `Cache-Control` 헤더다

서버는 `Cache-Control` 헤더로 더 유연한 캐시 제어를 지시할 수 있다.

`Expires` 보다 우선해서 처리된다.

먼저 서버가 응답으로 보내는 헤더를 소개한다.

- public: 같은 컴퓨터를 사용하는 복수의 사용자간 캐시 재사용을 허가한다.
- private: 같은 컴퓨터를 사용하는 다른 사용자 간 캐시를 재사용하지 않는다. 같은 URL에서 사용자마다 다른 콘텐츠가 돌아오는 경우에 이용한다
- max-age=n: 캐시의 신선도를 초단위로 설정. 86400을 지정하면 하루동안 캐시가 유효하고 서버에 문의하지 않고 캐시를 이용한다. 그 이후는 서버에 문의한 뒤 **304 Not Modified**가 반환됐을 때만 캐시를 이용한다.
- s-maxage=n: max-age 와같으나 공유 캐시에 대한 설정값
- no-cache: 캐시가 유효한지 매번 문의한다. max-age=0과 거의 같다.
- no-store: 캐시하지 않는다.

`no-cache`는 `Pragma`: `no-cache` 와 똑같이 캐시하지 않는 것은 아니고, 시간을 보고 서버에 접속하지 않은 채 콘텐츠를 재이용하는 것을 그만둘 뿐이다.

갱신 일자와 `ETag`를 사용하며, 서버가 304를 반환했을 때 이용하는 캐시는 유효하다. 캐시하지 않은 것은 `no-cache` 다.

캐시와 개인 정보 보호 관계도 주의해야한다.

`Cache-Control` 은 리로드를 억제하는 시스템이고, 개인 정보 보호 목적으로 사용할 수 없다.

`private` 는 같은 URL이 유저마다 다른 결과를 줄 경우에 이상한 결과가 되지 않도록 지시하는 것이다.

보안 접속이 아니면 통신 경로에서 내용이 보인다.

`no-store` 도 캐시 서버가 저장하지 않을 뿐 캐시 서버가 통신 내용 감시를 억제하는 기능은 없다.

콤마로 구분해 복수 지정이 가능하지만, 내용면에서 다음과 같이 조합한다.

- private, pulic 중 하나. 혹은 설정하지 않는다(기본은 private).
- max-age, s-maxage, no-cache, no-store 중 하나

### Cache-Control(2)

이미 `Pragma: no-cache` 부분에서 `별로 사용할 일이 없다` 라고 설명한 프록시에 대한 캐시 관련 요청이지만, `Cache-Control` 헤더를 요청 헤더에 포함함으로써 프록시에 지시할 수 있다.

서버에서 프록시로 보내는 응답 헤더에 사용할 수 있는 지시도 있다.

우선 클라이언트 측에서 요청 헤더에서 사용할 수 있는 설정값을 소개한다.

- no-cache: Pragma: `no-cache` 와 같다.
- no-store: 응답의 `no-cache` 와 같고, 프록시 서버에 캐시를 삭제하도록 요청
- max-age: 프록시에서 저장된 캐시가 최초로 저장되고 나서 저장 시간 이상 캐시는 사용하지 않도록 프록시에 요청
- max-stale: 지정한 시간만큼 유지 기간이 지났어도 클라이언트는 지정한 시간 동안은 저장된 캐시를 재사용하라고 프록시에 요청한다. 연장시간은 생략할 수 있고, 그런 경우 영원히 유효하다는 의미가 된다.
- min-fresh: 캐시의 수명이 지정된 시간 이상 남아 있을 때, 캐시를 보내도 좋다고 프록시에 요청한다. 즉 적어도 지정된 시간만큼은 신선해야한다.
- no-transform: 프록시가 콘텐츠를 변형하지 않도록 프록시에 요청
- only-if-cached: 캐시된 경우에만 응답을 반환하고, 캐시된 콘텐츠가 없을 땐 **504 Gateway Timeout** 오류 메시지를 반환하도록 프록시에 요청. 이 헤더가 설정되면 처음을 제외하고 오리진 서버에 전혀 엑세스 하지 않는다.

응답 헤더에서 서버가 프록시에 보내는 캐시 컨트롤 지시에는 다음과 같은 것이 있다.

- no-transform: 프록시가 콘텐츠를 변경하는 것을 제어한다.
- must-revalidate: `no-cache` 와 비슷하지만 프록시 서버에 보내는 지시가 된다. 프록시 서버가 서버에 문의했을 떄 서버의 응답이 없으면, 프록시 서버가 클라이언트에 **504 Gateway Timeou**t 이 반환되기를 기대한다.
- proxy-revalidate: `must-revalidate` 와 같지만, 공유 캐시에만 요청한다.
